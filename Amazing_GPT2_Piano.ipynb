{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Amazing-GPT2-Piano.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asigalov61/Amazing-GPT2-Piano/blob/master/Amazing_GPT2_Piano.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_8bcBYg638e",
        "colab_type": "text"
      },
      "source": [
        "### AMAZING GPT2 PIANO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPHhn4J66-Wg",
        "colab_type": "text"
      },
      "source": [
        "This is a slightly modified fork of Park Soochul Google Colab Notebook from his Music-GPT2 repo https://github.com/scpark20/Music-GPT-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RbuKWVe7U4-",
        "colab_type": "text"
      },
      "source": [
        "MAESTRO Dataset is courtesy of Google Magenta Team and it is distributed under Attribution-NonCommercial-ShareAlike 4.0 International license. So please keep it in mind and respect copyright please :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcKet2jTnSz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1695daeb-e3cf-4ecf-eded-4c92cd5d67dc"
      },
      "source": [
        "!pip install tensorflow==1.14\n",
        "!pip install numpy\n",
        "!pip install librosa\n",
        "!pip install tensorboardX\n",
        "!pip install tqdm\n",
        "!apt-get install swig\n",
        "!python3 setup.py install\n",
        "!pip install git+https://github.com/vishnubob/python-midi@feature/python3\n",
        "!pip install mido"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.30.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (49.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.18.5)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.8)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.16.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.15.0)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.48.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (49.2.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (49.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "swig is already the newest version (3.0.12-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "python3: can't open file 'setup.py': [Errno 2] No such file or directory\n",
            "Collecting git+https://github.com/vishnubob/python-midi@feature/python3\n",
            "  Cloning https://github.com/vishnubob/python-midi (to revision feature/python3) to /tmp/pip-req-build-8dhyd4_q\n",
            "  Running command git clone -q https://github.com/vishnubob/python-midi /tmp/pip-req-build-8dhyd4_q\n",
            "  Running command git checkout -b feature/python3 --track origin/feature/python3\n",
            "  Switched to a new branch 'feature/python3'\n",
            "  Branch 'feature/python3' set up to track remote branch 'feature/python3' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): midi==0.2.3 from git+https://github.com/vishnubob/python-midi@feature/python3 in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: midi\n",
            "  Building wheel for midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for midi: filename=midi-0.2.3-cp36-cp36m-linux_x86_64.whl size=280067 sha256=f1bce0ef3d25938d28fcb9069c6e3a4c67f0bd2de4cfea6330df05641dabefb2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9coft1eg/wheels/63/f9/4a/5e881f1126db389dfda75672c69b5be5bf51b0925cc7b5cbcf\n",
            "Successfully built midi\n",
            "Requirement already satisfied: mido in /usr/local/lib/python3.6/dist-packages (1.2.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "revrh_vNmsW7",
        "colab_type": "text"
      },
      "source": [
        "### Data Files Path Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92oBN0piprsn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "0e6138b4-8505-4aa6-89bc-4a22b6097d42"
      },
      "source": [
        "!wget 'https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip'\n",
        "!unzip -j /content/maestro-v2.0.0-midi.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-04 05:14:56--  https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 74.125.195.128, 74.125.20.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 59243107 (56M) [application/zip]\n",
            "Saving to: ‘maestro-v2.0.0-midi.zip.1’\n",
            "\n",
            "maestro-v2.0.0-midi 100%[===================>]  56.50M  66.3MB/s    in 0.9s    \n",
            "\n",
            "2020-08-04 05:14:57 (66.3 MB/s) - ‘maestro-v2.0.0-midi.zip.1’ saved [59243107/59243107]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-52b7a8a62031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wget 'https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unzip -j /content/maestro-v2.0.0-midi.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I4RxGd7msW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "# Modify this path to your own MAESTRO dataset\n",
        "maestro_dir = '/content'\n",
        "\n",
        "data_dirs = ['/content']\n",
        "#for year in ['2004', '2006', '2008', '2009', '2011', '2013', '2014', '2015', '2017', '2018']:\n",
        "#    data_dirs.append(maestro_dir + '/' + str(year))\n",
        "\n",
        "data_files = []\n",
        "for data_dir in data_dirs:\n",
        "    data_files += [join(data_dir, f) for f in listdir(data_dir) if isfile(join(data_dir, f)) if 'midi' in f]\n",
        "\n",
        "data_files.sort()\n",
        "\n",
        "print('total midi files : ', len(data_files))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuMBZycXmsXB",
        "colab_type": "text"
      },
      "source": [
        "### Event Extract from Midi File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jZYpAZTzmsXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mido\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_eventlist(data_file):\n",
        "    ON = 1\n",
        "    OFF = 0\n",
        "    CC = 2\n",
        "\n",
        "    midi = mido.MidiFile(data_file)\n",
        "\n",
        "    current_time = 0\n",
        "    eventlist = []\n",
        "    cc = False\n",
        "    for msg in midi:\n",
        "        #print(msg)\n",
        "        current_time += msg.time\n",
        "\n",
        "         # NOTE ON CASE\n",
        "        if msg.type is 'note_on' and msg.velocity > 0:\n",
        "            event = [current_time, ON, msg.note, msg.velocity]\n",
        "            eventlist.append(event)\n",
        "\n",
        "         # NOTE OFF CASE        \n",
        "        elif msg.type is 'note_off' or (msg.type is 'note_on' and msg.velocity == 0):\n",
        "            event = [current_time, OFF, msg.note, msg.velocity]\n",
        "            eventlist.append(event)\n",
        "            \n",
        "        if msg.type is 'control_change':\n",
        "            \n",
        "            if msg.control != 64:\n",
        "                continue\n",
        "            \n",
        "            if cc == False and msg.value > 0:\n",
        "                cc = True\n",
        "                event = [current_time, CC, 0, 1]\n",
        "                eventlist.append(event)\n",
        "                \n",
        "            elif cc == True and msg.value == 0:\n",
        "                cc = False\n",
        "                event = [current_time, CC, 0, 0]\n",
        "                eventlist.append(event)\n",
        "                \n",
        "    eventlist = np.array(eventlist)\n",
        "    return eventlist\n",
        "\n",
        "index = np.random.randint(0, len(data_files))\n",
        "print(index)\n",
        "eventlist = get_eventlist(data_files[index])\n",
        "print(eventlist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI6VSH4WmsXK",
        "colab_type": "text"
      },
      "source": [
        "### Midifile to EventListfile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "T8WAGDNdmsXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdm\n",
        "import os\n",
        "\n",
        "dataset_dir = 'dataset'\n",
        "\n",
        "if not os.path.exists(dataset_dir):\n",
        "    os.makedirs(dataset_dir)\n",
        "\n",
        "for i in tqdm(range(len(data_files))):\n",
        "    print(data_files[i])\n",
        "    eventlist = get_eventlist(data_files[i])\n",
        "    print(eventlist.shape)\n",
        "    \n",
        "    save_file = dataset_dir + '/' + str(i)\n",
        "    data = {'eventlist': eventlist}\n",
        "    np.savez(save_file, **data, allow_pickle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq-rwV6GuuU3",
        "colab_type": "text"
      },
      "source": [
        "### Data List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhCj9XyCmsXT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e091cb7-1188-431e-fa2f-2fe6b94e5a88"
      },
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import ntpath\n",
        "\n",
        "data_dirs = ['dataset']\n",
        "\n",
        "data_files = []\n",
        "\n",
        "for data_dir in data_dirs:\n",
        "    data_files += [join(data_dir, f) for f in listdir(data_dir) if isfile(join(data_dir, f)) if '.npz' in f]\n",
        "print(len(data_files))\n",
        "\n",
        "data_files.sort()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGl9MpcLwRR1",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameters Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBuEPvFvwW6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IntervalDim = 100\n",
        "\n",
        "VelocityDim = 32\n",
        "VelocityOffset = IntervalDim\n",
        "\n",
        "NoteOnDim = NoteOffDim = 128\n",
        "NoteOnOffset = IntervalDim + VelocityDim\n",
        "NoteOffOffset = IntervalDim + VelocityDim + NoteOnDim\n",
        "\n",
        "CCDim = 2\n",
        "CCOffset = IntervalDim + VelocityDim + NoteOnDim + NoteOffDim\n",
        "\n",
        "EventDim = IntervalDim + VelocityDim + NoteOnDim + NoteOffDim + CCDim # 390\n",
        "\n",
        "Time = 2000\n",
        "\n",
        "EmbeddingDim = 512\n",
        "\n",
        "HeadDim = 32\n",
        "Heads = 16\n",
        "ContextDim = HeadDim * Heads # 512\n",
        "\n",
        "Layers = 8"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-To1ss6wooF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "d7902483-a4b2-48f6-88df-436fe3f48e61"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.training import HParams\n",
        "\n",
        "def default_hparams():\n",
        "    return HParams(\n",
        "        n_vocab=EventDim,\n",
        "        n_ctx=ContextDim,\n",
        "        n_embd=EmbeddingDim,\n",
        "        n_head=Heads,\n",
        "        n_layer=Layers,\n",
        "        n_time=Time,\n",
        "    )\n",
        "\n",
        "hparams = default_hparams()\n",
        "print(hparams)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_vocab=390,n_ctx=512,n_embd=512,n_head=16,n_layer=8,n_time=2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23wnWV_swjWT",
        "colab_type": "text"
      },
      "source": [
        "### Load data from npz and converter to token sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpbE54wjwzgI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "b5e0b2f3-c489-479e-d5c4-fc04bfc28ba1"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "def get_data(length=Time):\n",
        "    index = np.random.randint(0, len(data_files))\n",
        "    data = np.load(data_files[index])['eventlist']\n",
        "    \n",
        "    # time augmentation\n",
        "    data[:, 0] *= np.random.uniform(0.80, 1.20)\n",
        "    \n",
        "    # absolute time to relative interval\n",
        "    data[1:, 0] = data[1:, 0] - data[:-1, 0]\n",
        "    data[0, 0] = 0\n",
        "    \n",
        "    # discretize interval into IntervalDim\n",
        "    data[:, 0] = np.clip(np.round(data[:, 0] * IntervalDim), 0, IntervalDim - 1)\n",
        "    \n",
        "    # Note augmentation\n",
        "    data[:, 2] += np.random.randint(-6, 6)\n",
        "    data[:, 2] = np.clip(data[:, 2], 0, NoteOnDim - 1)\n",
        "    \n",
        "    eventlist = []\n",
        "    for d in data:\n",
        "        # append interval\n",
        "        interval = d[0]\n",
        "        eventlist.append(interval)\n",
        "    \n",
        "        # note on case\n",
        "        if d[1] == 1:\n",
        "            velocity = (d[3] / 128) * VelocityDim + VelocityOffset\n",
        "            note = d[2] + NoteOnOffset\n",
        "            eventlist.append(velocity)\n",
        "            eventlist.append(note)\n",
        "            \n",
        "        # note off case\n",
        "        elif d[1] == 0:\n",
        "            note = d[2] + NoteOffOffset\n",
        "            eventlist.append(note)\n",
        "        # CC\n",
        "        elif d[1] == 2:\n",
        "            event = CCOffset + d[3]\n",
        "            eventlist.append(event)\n",
        "            \n",
        "    eventlist = np.array(eventlist).astype(np.int)\n",
        "    \n",
        "    if len(eventlist) > (length+1):\n",
        "        start_index = np.random.randint(0, len(eventlist) - (length+1))\n",
        "        eventlist = eventlist[start_index:start_index+(length+1)]\n",
        "        \n",
        "    # pad zeros\n",
        "    if len(eventlist) < (length+1):\n",
        "        pad = (length+1) - len(eventlist)\n",
        "        eventlist = np.pad(eventlist, (pad, 0), 'constant')\n",
        "        \n",
        "    x = eventlist[:length]\n",
        "    y = eventlist[1:length+1]\n",
        "    \n",
        "    return x, y\n",
        "    \n",
        "x, y = get_data()\n",
        "print('x shape : ', x.shape)\n",
        "print('y shape : ', y.shape)\n",
        "# print(x)\n",
        "# print(y)\n",
        "    \n",
        "    \n",
        "roll = np.zeros([len(x), EventDim])\n",
        "for t, _x in enumerate(x):\n",
        "    roll[t, _x] = 1\n",
        "\n",
        "plt.figure(figsize=[18, 15])\n",
        "librosa.display.specshow(roll.T)\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x shape :  (2000,)\n",
            "y shape :  (2000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x1080 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHxOpCHRxD5Z",
        "colab_type": "text"
      },
      "source": [
        "### GPT-2 source code from https://github.com/openai/gpt-2/blob/master/src/model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3rKfrGUxLCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shape_list(x):\n",
        "    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
        "    static = x.shape.as_list()\n",
        "    dynamic = tf.shape(x)\n",
        "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
        "\n",
        "def softmax(x, axis=-1):\n",
        "    x = x - tf.reduce_max(x, axis=axis, keepdims=True)\n",
        "    ex = tf.exp(x)\n",
        "    return ex / tf.reduce_sum(ex, axis=axis, keepdims=True)\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))\n",
        "\n",
        "def norm(x, scope, *, axis=-1, epsilon=1e-5):\n",
        "    \"\"\"Normalize to mean = 0, std = 1, then do a diagonal affine transform.\"\"\"\n",
        "    with tf.variable_scope(scope):\n",
        "        n_state = x.shape[-1].value\n",
        "        g = tf.get_variable('g', [n_state], initializer=tf.constant_initializer(1))\n",
        "        b = tf.get_variable('b', [n_state], initializer=tf.constant_initializer(0))\n",
        "        u = tf.reduce_mean(x, axis=axis, keepdims=True)\n",
        "        s = tf.reduce_mean(tf.square(x-u), axis=axis, keepdims=True)\n",
        "        x = (x - u) * tf.rsqrt(s + epsilon)\n",
        "        x = x*g + b\n",
        "        return x\n",
        "\n",
        "def split_states(x, n):\n",
        "    \"\"\"Reshape the last dimension of x into [n, x.shape[-1]/n].\"\"\"\n",
        "    *start, m = shape_list(x)\n",
        "    return tf.reshape(x, start + [n, m//n])\n",
        "\n",
        "def merge_states(x):\n",
        "    \"\"\"Smash the last two dimensions of x into a single dimension.\"\"\"\n",
        "    *start, a, b = shape_list(x)\n",
        "    return tf.reshape(x, start + [a*b])\n",
        "\n",
        "def conv1d(x, scope, nf, *, w_init_stdev=0.02):\n",
        "    with tf.variable_scope(scope):\n",
        "        *start, nx = shape_list(x)\n",
        "        w = tf.get_variable('w', [1, nx, nf], initializer=tf.random_normal_initializer(stddev=w_init_stdev))\n",
        "        b = tf.get_variable('b', [nf], initializer=tf.constant_initializer(0))\n",
        "        c = tf.reshape(tf.matmul(tf.reshape(x, [-1, nx]), tf.reshape(w, [-1, nf]))+b, start+[nf])\n",
        "        return c\n",
        "\n",
        "def attention_mask(nd, ns, *, dtype):\n",
        "    \"\"\"1's in the lower triangle, counting from the lower right corner.\n",
        "    Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n",
        "    \"\"\"\n",
        "    i = tf.range(nd)[:,None]\n",
        "    j = tf.range(ns)\n",
        "    m = i >= j - ns + nd\n",
        "    return tf.cast(m, dtype)\n",
        "\n",
        "'''\n",
        "MEMORY EFFICIENT IMPLEMENTATION OF RELATIVE POSITION-BASED ATTENTION\n",
        "(Music Transformer, Cheng-Zhi Anna Huang et al. 2018)\n",
        "'''\n",
        "def attn(x, scope, n_state, *, hparams):\n",
        "    assert x.shape.ndims == 3  # Should be [batch, sequence, features]\n",
        "    assert n_state % hparams.n_head == 0\n",
        "\n",
        "    def split_heads(x):\n",
        "        # From [batch, sequence, features] to [batch, heads, sequence, features]\n",
        "        return tf.transpose(split_states(x, hparams.n_head), [0, 2, 1, 3])\n",
        "\n",
        "    def merge_heads(x):\n",
        "        # Reverse of split_heads\n",
        "        return merge_states(tf.transpose(x, [0, 2, 1, 3]))\n",
        "\n",
        "    def mask_attn_weights(w):\n",
        "        # w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.\n",
        "        _, _, nd, ns = shape_list(w)\n",
        "        b = attention_mask(nd, ns, dtype=w.dtype)\n",
        "        b = tf.reshape(b, [1, 1, nd, ns])\n",
        "        w = w*b - tf.cast(1e10, w.dtype)*(1-b)\n",
        "        return w\n",
        "    \n",
        "    def relative_attn(q):\n",
        "        # q have shape [batch, heads, sequence, features]\n",
        "        batch, heads, sequence, features = shape_list(q)\n",
        "        E = tf.get_variable('E', [heads, sequence, features])\n",
        "        # [heads, batch, sequence, features]\n",
        "        q_ = tf.transpose(q, [1, 0, 2, 3])\n",
        "        # [heads, batch * sequence, features]\n",
        "        q_ = tf.reshape(q_, [heads, batch * sequence, features])\n",
        "        # [heads, batch * sequence, sequence]\n",
        "        rel = tf.matmul(q_, E, transpose_b=True)\n",
        "        # [heads, batch, sequence, sequence]\n",
        "        rel = tf.reshape(rel, [heads, batch, sequence, sequence])\n",
        "        # [heads, batch, sequence, 1+sequence]\n",
        "        rel = tf.pad(rel, ((0, 0), (0, 0), (0, 0), (1, 0)))\n",
        "        # [heads, batch, sequence+1, sequence]\n",
        "        rel = tf.reshape(rel, (heads, batch, sequence+1, sequence))\n",
        "        # [heads, batch, sequence, sequence]\n",
        "        rel = rel[:, :, 1:]\n",
        "        # [batch, heads, sequence, sequence]\n",
        "        rel = tf.transpose(rel, [1, 0, 2, 3])\n",
        "        return rel\n",
        "        \n",
        "    def multihead_attn(q, k, v):\n",
        "        # q, k, v have shape [batch, heads, sequence, features]\n",
        "        w = tf.matmul(q, k, transpose_b=True)\n",
        "        w = w + relative_attn(q)\n",
        "        w = w * tf.rsqrt(tf.cast(v.shape[-1].value, w.dtype))\n",
        "\n",
        "        w = mask_attn_weights(w)\n",
        "        w = softmax(w)\n",
        "        a = tf.matmul(w, v)\n",
        "        return a\n",
        "\n",
        "    with tf.variable_scope(scope):\n",
        "        c = conv1d(x, 'c_attn', n_state*3)\n",
        "        q, k, v = map(split_heads, tf.split(c, 3, axis=2))\n",
        "        present = tf.stack([k, v], axis=1)\n",
        "\n",
        "        a = multihead_attn(q, k, v)\n",
        "        a = merge_heads(a)\n",
        "        a = conv1d(a, 'c_proj', n_state)\n",
        "        return a, present\n",
        "\n",
        "\n",
        "def mlp(x, scope, n_state, *, hparams):\n",
        "    with tf.variable_scope(scope):\n",
        "        nx = x.shape[-1].value\n",
        "        h = gelu(conv1d(x, 'c_fc', n_state))\n",
        "        h2 = conv1d(h, 'c_proj', nx)\n",
        "        return h2\n",
        "\n",
        "\n",
        "def block(x, scope, *, hparams):\n",
        "    with tf.variable_scope(scope):\n",
        "        nx = x.shape[-1].value\n",
        "        a, present = attn(norm(x, 'ln_1'), 'attn', nx, hparams=hparams)\n",
        "        x = x + a\n",
        "        m = mlp(norm(x, 'ln_2'), 'mlp', nx*4, hparams=hparams)\n",
        "        x = x + m\n",
        "        return x, present\n",
        "\n",
        "def expand_tile(value, size):\n",
        "    \"\"\"Add a new axis of given size.\"\"\"\n",
        "    value = tf.convert_to_tensor(value, name='value')\n",
        "    ndims = value.shape.ndims\n",
        "    return tf.tile(tf.expand_dims(value, axis=0), [size] + [1]*ndims)\n",
        "\n",
        "def model(hparams, X, scope='model', reuse=False):\n",
        "    with tf.variable_scope(scope, reuse=reuse):\n",
        "        results = {}\n",
        "        batch, sequence = shape_list(X)\n",
        "\n",
        "        wte = tf.get_variable('wte', [hparams.n_vocab, hparams.n_embd],\n",
        "                             initializer=tf.random_normal_initializer(stddev=0.02))\n",
        "        h = tf.gather(wte, X)\n",
        "\n",
        "        # Transformer\n",
        "        presents = []\n",
        "        for layer in range(hparams.n_layer):\n",
        "            h, present = block(h, 'h%d' % layer, hparams=hparams)\n",
        "            presents.append(present)\n",
        "        results['present'] = tf.stack(presents, axis=1)\n",
        "        h = norm(h, 'ln_f')\n",
        "\n",
        "        # Language model loss.  Do tokens <n predict token n?\n",
        "        h_flat = tf.reshape(h, [batch*sequence, hparams.n_embd])\n",
        "        logits = tf.matmul(h_flat, wte, transpose_b=True)\n",
        "        logits = tf.reshape(logits, [batch, sequence, hparams.n_vocab])\n",
        "        results['logits'] = logits\n",
        "        return results"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceWY7pbDxZpZ",
        "colab_type": "text"
      },
      "source": [
        "### Draw Main Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE1NUmfSxYYH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "8580ed80-304e-4005-cae1-8e135a176f77"
      },
      "source": [
        "hparams = default_hparams()\n",
        "print(hparams)\n",
        "\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "X = tf.placeholder(tf.int32, [None, hparams.n_time])\n",
        "Y = tf.placeholder(tf.int32, [None, hparams.n_time])\n",
        "\n",
        "X_onehot = tf.one_hot(X, axis=2, depth=hparams.n_vocab)\n",
        "\n",
        "logits = model(hparams, X)['logits']\n",
        "probs = tf.nn.softmax(logits, axis=2)\n",
        "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y, logits=logits)\n",
        "loss = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "#temperature = tf.Variable(1., name='temperature')\n",
        "temperature = 0\n",
        "u = tf.random.uniform(shape=tf.shape(logits[:, -1]), minval=1e-5, maxval=1.-1e-5)\n",
        "u = (logits[:, -1] - tf.log(temperature + 1e-8)) - tf.log(-tf.log(u))\n",
        "sample = tf.argmax(u, axis=1)\n",
        "\n",
        "#dist = tf.distributions.Categorical(logits=logits[:, -1])\n",
        "#sample = dist.sample()\n",
        "\n",
        "'''\n",
        "Train\n",
        "'''\n",
        "global_step = tf.Variable(0, name='global_step')\n",
        "learning_rate = tf.Variable(1e-3, name='learning_rate')\n",
        "train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step)\n",
        "\n",
        "'''\n",
        "Session Open\n",
        "'''\n",
        "\n",
        "\n",
        "# GPU number to use\n",
        "gpu_options = tf.GPUOptions(visible_device_list=\"0\")\n",
        "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
        "\n",
        "# config = tf.ConfigProto(device_count = {'GPU': 0})\n",
        "# sess = tf.Session(config=config)\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "print('graph create')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_vocab=390,n_ctx=512,n_embd=512,n_head=16,n_layer=8,n_time=2000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "graph create\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0umXARBoxX-5",
        "colab_type": "text"
      },
      "source": [
        "### Load model if exist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9l-3uNDxs-S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e645da3-9173-454f-fdf4-eb372d443a2a"
      },
      "source": [
        "import tensorflow.contrib.slim as slim\n",
        "from tensorflow.python import pywrap_tensorflow\n",
        "\n",
        "load_dir = 'save/gpt2-cc-interval100-attention2000-midi'\n",
        "save_dir = 'save/gpt2-cc-interval100-attention2000-midi'\n",
        "\n",
        "def get_variables_from_checkpoint_file(file_name):\n",
        "    variables = []\n",
        "    reader = pywrap_tensorflow.NewCheckpointReader(file_name)\n",
        "\n",
        "    var_to_shape_map = reader.get_variable_to_shape_map()\n",
        "    for key in sorted(var_to_shape_map):\n",
        "        variables.append((key, var_to_shape_map[key]))\n",
        "\n",
        "    return variables\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "if True:\n",
        "    restore_file = tf.train.latest_checkpoint(load_dir)\n",
        "    if restore_file is not None:\n",
        "        try:\n",
        "            saver.restore(sess, restore_file)\n",
        "            print(\"Model restored.\", restore_file)\n",
        "        except:\n",
        "            saved_variables = get_variables_from_checkpoint_file(restore_file)\n",
        "            model_variables = slim.get_variables_to_restore()\n",
        "            restore_variables = []\n",
        "            for model_variable in model_variables:\n",
        "                for saved_variable_name, saved_variable_shape in saved_variables:\n",
        "                    model_variable_name = model_variable.name.split(\":\")[0]\n",
        "                    if saved_variable_name == model_variable_name and tuple(saved_variable_shape) == model_variable.shape:\n",
        "                        restore_variables.append(model_variable)\n",
        "\n",
        "            init_saver = tf.train.Saver(restore_variables)\n",
        "            init_saver.restore(sess, restore_file)\n",
        "            print(\"Model partially restored.\")\n",
        "    else:\n",
        "        print('model not exist.')\n",
        "        "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model not exist.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5t6m_sMx1rB",
        "colab_type": "text"
      },
      "source": [
        "### TensorboardX Logger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ksgK4aAx2u5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "class Logger(SummaryWriter):\n",
        "    def __init__(self, logdir):\n",
        "        super(Logger, self).__init__(logdir)\n",
        "\n",
        "    def log(self, log_string, value, iteration):\n",
        "            self.add_scalar(log_string, value, iteration)\n",
        "            \n",
        "logger = Logger(save_dir)            \n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOHlruxmx7mJ",
        "colab_type": "text"
      },
      "source": [
        "### Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRtJ8rMSyC_F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2711ed89-1c6e-416b-943c-ac94c8a0739d"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from time import sleep\n",
        "import time\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "while(True):\n",
        "    for _ in range(100):\n",
        "        _inputs = []\n",
        "        _targets = []\n",
        "        for _ in range(batch_size):\n",
        "            while(True):\n",
        "                x, y = get_data(hparams.n_time)\n",
        "                if(x.shape == y.shape):\n",
        "                    break\n",
        "                 \n",
        "            _inputs.append(x)\n",
        "            _targets.append(y)\n",
        "        _inputs = np.stack(_inputs)\n",
        "        _targets = np.stack(_targets)\n",
        "        print(_inputs.shape, _targets.shape)\n",
        "        \n",
        "        _, _global_step, _loss = sess.run([train_step, global_step, loss], \n",
        "                                          feed_dict={X: _inputs, \n",
        "                                                     Y: _targets,\n",
        "                                                     learning_rate: 1e-3})\n",
        "        print(_global_step, _loss)\n",
        "        \n",
        "        if _global_step % 10 == 0:\n",
        "            logger.log('loss', _loss, _global_step)\n",
        "        \n",
        "        if _global_step % 1000 == 0:\n",
        "            save_path = saver.save(sess, save_dir + '/checkpoint', global_step=_global_step)\n",
        "            print(\"Model saved in path: %s\" % save_path)\n",
        "        \n",
        "    clear_output()\n",
        "    \n",
        "    _inputs_onehot, _probs = sess.run([X_onehot, probs], feed_dict={X: _inputs})\n",
        "    \n",
        "    plt.figure(figsize=[18, 8])\n",
        "    librosa.display.specshow(_inputs_onehot[0].T)\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure(figsize=[18, 8])\n",
        "    librosa.display.specshow(_probs[0].T)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 2000) (1, 2000)\n",
            "1 6.212532\n",
            "(1, 2000) (1, 2000)\n",
            "2 5.4553576\n",
            "(1, 2000) (1, 2000)\n",
            "3 5.1257854\n",
            "(1, 2000) (1, 2000)\n",
            "4 4.890157\n",
            "(1, 2000) (1, 2000)\n",
            "5 4.828839\n",
            "(1, 2000) (1, 2000)\n",
            "6 4.8093476\n",
            "(1, 2000) (1, 2000)\n",
            "7 4.560104\n",
            "(1, 2000) (1, 2000)\n",
            "8 4.549266\n",
            "(1, 2000) (1, 2000)\n",
            "9 4.646846\n",
            "(1, 2000) (1, 2000)\n",
            "10 4.3504705\n",
            "(1, 2000) (1, 2000)\n",
            "11 4.734865\n",
            "(1, 2000) (1, 2000)\n",
            "12 4.437431\n",
            "(1, 2000) (1, 2000)\n",
            "13 4.7623096\n",
            "(1, 2000) (1, 2000)\n",
            "14 4.7836847\n",
            "(1, 2000) (1, 2000)\n",
            "15 4.4175777\n",
            "(1, 2000) (1, 2000)\n",
            "16 4.8268085\n",
            "(1, 2000) (1, 2000)\n",
            "17 4.7599564\n",
            "(1, 2000) (1, 2000)\n",
            "18 4.7518115\n",
            "(1, 2000) (1, 2000)\n",
            "19 4.74509\n",
            "(1, 2000) (1, 2000)\n",
            "20 4.7194157\n",
            "(1, 2000) (1, 2000)\n",
            "21 4.670304\n",
            "(1, 2000) (1, 2000)\n",
            "22 4.335082\n",
            "(1, 2000) (1, 2000)\n",
            "23 4.4760118\n",
            "(1, 2000) (1, 2000)\n",
            "24 4.759334\n",
            "(1, 2000) (1, 2000)\n",
            "25 4.8128977\n",
            "(1, 2000) (1, 2000)\n",
            "26 4.563635\n",
            "(1, 2000) (1, 2000)\n",
            "27 4.925359\n",
            "(1, 2000) (1, 2000)\n",
            "28 4.543837\n",
            "(1, 2000) (1, 2000)\n",
            "29 4.4734325\n",
            "(1, 2000) (1, 2000)\n",
            "30 4.84535\n",
            "(1, 2000) (1, 2000)\n",
            "31 4.8345037\n",
            "(1, 2000) (1, 2000)\n",
            "32 4.581549\n",
            "(1, 2000) (1, 2000)\n",
            "33 5.1950803\n",
            "(1, 2000) (1, 2000)\n",
            "34 4.533926\n",
            "(1, 2000) (1, 2000)\n",
            "35 4.696515\n",
            "(1, 2000) (1, 2000)\n",
            "36 4.6196313\n",
            "(1, 2000) (1, 2000)\n",
            "37 4.73332\n",
            "(1, 2000) (1, 2000)\n",
            "38 4.5841956\n",
            "(1, 2000) (1, 2000)\n",
            "39 4.904703\n",
            "(1, 2000) (1, 2000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVDIEKgB6TWR",
        "colab_type": "text"
      },
      "source": [
        "### Output MIDI file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwgMdlHx6sCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import tensorflow.contrib.slim as slim\n",
        "from tensorflow.python import pywrap_tensorflow\n",
        "\n",
        "load_dir = 'save/gpt2-cc-interval100-attention2000-midi'\n",
        "save_dir = 'save/gpt2-cc-interval100-attention2000-midi'\n",
        "\n",
        "def get_variables_from_checkpoint_file(file_name):\n",
        "    variables = []\n",
        "    reader = pywrap_tensorflow.NewCheckpointReader(file_name)\n",
        "\n",
        "    var_to_shape_map = reader.get_variable_to_shape_map()\n",
        "    for key in sorted(var_to_shape_map):\n",
        "        variables.append((key, var_to_shape_map[key]))\n",
        "\n",
        "    return variables\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "if True:\n",
        "    restore_file = tf.train.latest_checkpoint(load_dir)\n",
        "    if restore_file is not None:\n",
        "        try:\n",
        "            saver.restore(sess, restore_file)\n",
        "            print(\"Model restored.\", restore_file)\n",
        "        except:\n",
        "            saved_variables = get_variables_from_checkpoint_file(restore_file)\n",
        "            model_variables = slim.get_variables_to_restore()\n",
        "            restore_variables = []\n",
        "            for model_variable in model_variables:\n",
        "                for saved_variable_name, saved_variable_shape in saved_variables:\n",
        "                    model_variable_name = model_variable.name.split(\":\")[0]\n",
        "                    if saved_variable_name == model_variable_name and tuple(saved_variable_shape) == model_variable.shape:\n",
        "                        restore_variables.append(model_variable)\n",
        "\n",
        "            init_saver = tf.train.Saver(restore_variables)\n",
        "            init_saver.restore(sess, restore_file)\n",
        "            print(\"Model partially restored.\")\n",
        "    else:\n",
        "        print('model not exist.')\n",
        "\n",
        "N = 6000\n",
        "\n",
        "x, y = get_data(hparams.n_time)\n",
        "_inputs = np.zeros([1, N], dtype=np.int32)\n",
        "_inputs[:, :len(x)] = x[None, :]\n",
        "print(_inputs)\n",
        "\n",
        "for i in tqdm(range(N-Time)):\n",
        "\n",
        "    _sample, _prob = sess.run([sample, probs], feed_dict={X: _inputs[:, i:i+Time]})\n",
        "    _inputs[:, i+Time] = _sample \n",
        "\n",
        "print(_inputs.shape)\n",
        "\n",
        "class Event():\n",
        "    def __init__(self, time, note, cc, on, velocity):\n",
        "        self.time = time\n",
        "        self.note = note\n",
        "        self.on = on\n",
        "        self.cc = cc\n",
        "        self.velocity = velocity\n",
        "\n",
        "    def get_event_sequence(self):\n",
        "        return [self.time, self.note, int(self.on)]\n",
        "\n",
        "class Note():\n",
        "    def __init__(self):\n",
        "        self.pitch = 0\n",
        "        self.start_time = 0\n",
        "        self.end_time = 0\n",
        "\n",
        "event_list = []\n",
        "time = 0\n",
        "event = None\n",
        "\n",
        "EventDim = IntervalDim + VelocityDim + NoteOnDim + NoteOffDim # 388\n",
        "\n",
        "for _input in _inputs[0]:\n",
        "    # interval\n",
        "    if _input < IntervalDim: \n",
        "        time += _input\n",
        "        event = Event(time, 0, False, 0, 0)\n",
        "\n",
        "    # velocity\n",
        "    elif _input < NoteOnOffset:\n",
        "        if event is None:\n",
        "            continue\n",
        "        event.velocity = (_input - VelocityOffset) / VelocityDim * 128\n",
        "        #print('velocity : ', event.velocity)\n",
        "\n",
        "    # note on\n",
        "    elif _input < NoteOffOffset:\n",
        "        if event is None:\n",
        "            continue\n",
        "\n",
        "        event.note = _input - NoteOnOffset\n",
        "        event.on = True\n",
        "        event_list.append(event)\n",
        "        #event_list.append(Event(event.time + 100, event.note, False))\n",
        "        event = None\n",
        "\n",
        "    # note off\n",
        "    elif _input < CCOffset:\n",
        "        if event is None:\n",
        "            continue\n",
        "        event.note = _input - NoteOffOffset\n",
        "        event.on = False\n",
        "        event_list.append(event)\n",
        "        event = None\n",
        "\n",
        "    ## CC\n",
        "    else:\n",
        "        if event is None:\n",
        "            continue\n",
        "        event.cc = True\n",
        "        on = _input - CCOffset == 1\n",
        "        event.on = on\n",
        "        #print(on)\n",
        "        event_list.append(event)\n",
        "        event = None\n",
        "\n",
        "import midi\n",
        "# Instantiate a MIDI Pattern (contains a list of tracks)\n",
        "pattern = midi.Pattern()\n",
        "# Instantiate a MIDI Track (contains a list of MIDI events)\n",
        "track = midi.Track()\n",
        "# Append the track to the pattern\n",
        "pattern.append(track)\n",
        "\n",
        "prev_time = 0\n",
        "pitches = [None for _ in range(128)]\n",
        "for event in event_list:\n",
        "    tick = (event.time - prev_time) * 5\n",
        "    prev_time = event.time\n",
        "\n",
        "    # case NOTE:\n",
        "    if not event.cc:\n",
        "        if event.on:\n",
        "            if pitches[event.note] is not None:\n",
        "                # Instantiate a MIDI note off event, append it to the track\n",
        "                off = midi.NoteOffEvent(tick=0, pitch=event.note)\n",
        "                track.append(off)\n",
        "                pitches[event.note] = None\n",
        "\n",
        "            # Instantiate a MIDI note on event, append it to the track\n",
        "            on = midi.NoteOnEvent(tick=tick, velocity=int(event.velocity), pitch=event.note)\n",
        "            track.append(on)\n",
        "            pitches[event.note] = prev_time\n",
        "        else:\n",
        "            # Instantiate a MIDI note off event, append it to the track\n",
        "            off = midi.NoteOffEvent(tick=tick, pitch=event.note)\n",
        "            track.append(off)\n",
        "            pitches[event.note] = None\n",
        "\n",
        "    # case CC:\n",
        "    elif event.cc:\n",
        "        if event.on:\n",
        "            cc = midi.ControlChangeEvent(tick=tick, control=64, value=64)\n",
        "        else:\n",
        "            cc = midi.ControlChangeEvent(tick=tick, control=64, value=0)\n",
        "\n",
        "        track.append(cc)\n",
        "\n",
        "    for pitch in range(128):\n",
        "        if pitches[pitch] is not None and pitches[pitch] + 100 < prev_time:\n",
        "            #print('here')\n",
        "            off = midi.NoteOffEvent(tick=0, pitch=pitch)\n",
        "            track.append(off)\n",
        "            pitches[pitch] = None\n",
        "\n",
        "\n",
        "# Add the end of track event, append it to the track\n",
        "eot = midi.EndOfTrackEvent(tick=1)\n",
        "track.append(eot)\n",
        "# Print out the pattern\n",
        "#print(pattern)\n",
        "# Save the pattern to disk\n",
        "midi.write_midifile(\"output_file.mid\", pattern)\n",
        "\n",
        "print('done')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}